# Инференс модели на PySpark и Kafka

## Настроить кластер Kafka

1) В Yandex Cloud создать Managed Service for Kafka (зона доступности - ru-central1-b, выбрать любую сеть или default, выбрать группу безопасности, которая имеет настройки как в проекте airflow_dataproc_mlflow_validation, разрешить публичный доступ)

2) При создании группа безопасности должна иметь следующие настройки (как минимум):

Исходящий трафик:
| Протокол | Диапазон портов | Тип назначения       | Назначение    | Описание    |
|----------|-----------------|----------------------|---------------|-------------|
| Any	   | 0-65535	     |	Группа безопасности |	Self	    |  —          |
| Any	   | 0-65535		 |	CIDR				|	0.0.0.0/0   |  —          |

Входящий трафик:
| Протокол | Диапазон портов |	Тип источника       | Источник      | Описание    |
|----------|-----------------|----------------------|---------------|-------------|
| Any	   | 0-65535		 |	Группа безопасности	|	Self	    | input       |
| TCP	   | 9092    		 |  CIDR				|	0.0.0.0/0   | kafka plain |
| Any	   | 9091			 |  CIDR				|	0.0.0.0/0   | kafka ssl   |
| ICMP	   | —				 |  CIDR				|	0.0.0.0/0   | ping        |

3) Зайти в созданный кластер, нажать кнопку "Подключиться", скопировать FQDN и использовать его в параметрах подключения (18 строка в kafka_consumer.py и 29 строка в kafka_producer.py)

4) Скачать корневой сертификат для обмена данными по SSL (ссылка: https://cloud.yandex.ru/docs/managed-kafka/operations/connect#get-ssl-cert) . Файл YandexCA.crt положить в директорию со скриптами

5) Создать топики "features" и "predictions"

6) Создать пользователя (задать имя "mlops", пароль "otus-mlops", добавить роли consumer и producer для созданных топиков)

7) Установить библиотеку kafka-python

		pip install kafka-python

8) Запустить 1-й consumer

		python3 kafka_consumer.py -g otus

9) Запустить 2-й consumer

		python3 kafka_consumer.py -g otus

10) Запустить producer

		python3 kafka_producer.py -n 100

## Настроить кластер Data Proc

11) В качестве кластра использовать 






