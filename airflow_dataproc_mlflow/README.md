### Автоматический запуск скриптов на кластере Data Proc через AirFlow

На кластере DataProc Через AirFlow запускаются скрипты генерации данных, сохранения данных в HDFS и предобработки данных с помощью PySpark и обучения модели с логгированием в MLFLOW

Важно: ВМ с AirFlow и кластер Data Proc должны находиться в одной сети и иметь одну и ту же группу безопасности

1) Создать виртуальную машину (Compute Cloud) с AirFlow
2) При создании группа безопасности должна иметь следующие настройки:

Исходящий трафик:
| Протокол | Диапазон портов | Тип назначения       | Назначение    | Описание    |
|----------|-----------------|----------------------|---------------|-------------|
| Any	   | 0-65535	     |	Группа безопасности |	Self	    |  —          |
| Any	   | 0-65535		 |	CIDR				|	0.0.0.0/0   |  —          |

Входящий трафик:
| Протокол | Диапазон портов |	Тип источника       | Источник      | Описание    |
|----------|-----------------|----------------------|---------------|-------------|
| Any	   | 0-65535		 |	Группа безопасности	|	Self	    | input       |
| TCP	   | 22				 |  CIDR				|	0.0.0.0/0   | SSH         |
| ICMP	   | —				 |  CIDR				|	0.0.0.0/0   | ping        |
| TCP	   | 80				 |  CIDR				|	0.0.0.0/0   | HTTP        |
| TCP	   | 443			 |  CIDR				|	0.0.0.0/0   | HTTPS       |
| Any	   | 8888			 |  CIDR				|	0.0.0.0/0   | Jupyter     |
| Any	   | 4040-4050   	 |  CIDR				|	0.0.0.0/0   | Spark WebUI |
| Any      | 8000            |  CIDR                |   0.0.0.0/0   | MLFlow      |


3) Подключиться по SSH с локальной машины и скопировать логин/пароль для подключения к AirFlow через web-интерфейс

		ssh dima@51.250.23.122

4) Переконфигурируем AirFlow, внеся изменения в /etc/airflow/airflow.cfg (чтобы выводилось меньше ненужной информации, напр. примеры DAG'ов)

		sudo nano /etc/airflow/airflow.cfg

	load_examples = False
	load_default_connections = False

	Сохраняем изменения и перезапускаем виртуальную машину (если веб интерфейс недоступен, пробуем другой браузер)

5) Генерируем SSH ключи на ВМ с AirFlow
	
		ssh-keygen

6) Переносим приватный ключ на директорию выше и присваиваем полный доступ (чтобы AirFlow мог его считать)

		cp .ssh/id_rsa ./
		sudo chmod 777 id_rsa

7) Копируем содержимое открытого ключа (он необходим при создании кластера Data Proc)

		cat .ssh/id_rsa.pub

	Выделяем ключ и ctrl+shift+c

8) Создать кластер Data Proc:
 - при создании группа безопасности должна иметь такие же настройки, как и ВМ с AirFlow;
 - в качестве SSH ключа использовать открытый ключ ВМ с AirFlow (можно также добавить SSH своего ПК и открыть IP мастерноды внешнему миру, но это не рекомендуется);

9) Подключиться к мастерноде из консоли AirFlow можно по внутреннему IP адресу, можно по внешнему, если внешний ip был разрешен при создании кластера

		ssh ubuntu@10.129.0.33

10) Склонировать репозиторий, содержащий необходимый скрипт

		sudo apt update
		sudo apt install git
		git clone https://github.com/fds-git/MLOps.git

11) Установить необходимые библиотеки (через sudo, иначе скрипт генерации run_generate_script.py не запустится на кластере так как не увидит numpy, pandas и т.д.)

		sudo apt install python3-pip
		sudo pip install numpy
		sudo pip install pandas
		sudo pip install fastparquet
		#sudo pip install findspark

12) Создаем директорию в hdfs для сохранения данных, которые будут генерироваться

		hdfs dfs -mkdir /user/testdata
		hdfs dfs -mkdir /user/processed_data

13) Возвращаемся в консоль AirFlow и устанавливаем SSH провайдер

		sudo apt install python3-pip
		sudo pip install apache-airflow-providers-ssh (через sudo, иначе в веб интерфейте ошибка, что provider не обнаружен, т.к. AirFlow запущен от пользователя airflow)

	Если после последней команды веб-интерфейс станет недоступным, надо ввести команду:

		airflow webserver -p 80

	И затем отключиться от ВМ и снова в ней подключиться, веб интерфейс должен заработать.

	То же самое надо сделать с командой

		airflow scheduler - (Чтобы DAG запускался)

14) Проверяем, что провайдер установился
		
		sudo airflow providers list
		
15) Создаем новый DAG

		sudo nano /home/airflow/dags/run_generate_script.py

	Копируем содержимое run_generate_script.py из репозитория MLOps/airflow_dataproc_gen_process_data/for_airflow в только что созданный run_generate_script.py и сохраняем изменения (не забыть проверить, что remote_host в SSHHook соответствует внутреннему IP адресу мастерноды)

16) Подключиться к AirFlow через web-интерфейс (логин и пароль находятся в консоли подключения к AirFlow по SSH)

		http://51.250.23.122:80/

	Здесь должны увидеть новый DAG generate_data

17) Запускаем переключателем DAG. Через некоторое время можем увидеть выполненные экземпляры DAG'a, внутри будут выполненные таски run_generate, в логах можно посмотреть результаты работы.

18) Через консоль мастерноды проверим, что сгенерированыые данные появляются в HDFS

		hdfs dfs -ls /user/testdata - сырые данные (сгенерированные)
		hdfs dfs -ls /user/processed_data - предобработанные данные

Обратить внимание:
- если библиотека была установлена через sudo (sudo pip install numpy), то и скрипт надо вызывать через sudo (sudo python3 script.py), либо в обоих случаях без sudo;
- провайдеры в AirFlow устанавливать только через sudo, т.к. web-интерфейс, запускается через пользователя airflow и в противном случае не подтянет новые провайдеры;
- если в AirFlow в качестве команды хотим передать через SSHOperator запуск скрипта, например ('bash generate.sh '), то после .sh всегда пробел, иначе - ошибка;
- в date.txt после даты не должно быть пробелов, иначе - ошибка.

Если необходимо запустить jupyter notebook на кластере, то необходим внешний IP на местерноде и чтобы открытый ключ локального компа лежал на местерноде, далее вводим команду в консоли мастерноды:

		jupyter notebook --no-browser --port=8888

На локальном компе пробросить ssh туннель

		ssh -L 8888:localhost:8888 ubuntu@51.250.21.57

Если в jupyter ошибка при import findspark, то установить findspark без sudo и перезапустить jupyter

Если в AirFlow ошибка, связанная с ssh timeout при создании спарк сессии (spark = SparkSession.builder.appName("Feature").getOrCreate()), попробовать перезагрузить кластер Data Proc

Если в AirFlow ошибка, связанная с import ssh, попробовать перезагрузить ВМ AirFlow

To Do: 13 пункт: может можно без команд просто перезайти и веб интерфейс заработает?