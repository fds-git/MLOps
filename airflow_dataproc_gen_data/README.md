### Автоматический запуск скриптов на кластере Data Proc через AirFlow

Важно: ВМ с AirFlow и кластер Data Proc должны находиться в одной сети и иметь одну и ту же группу безопасности

1) Создать виртуальную машину (Compute Cloud) с AirFlow
2) При создании группа безопасности должна иметь следующие настройки:

Исходящий трафик:
| Протокол | Диапазон портов | Тип назначения       | Назначение    | Описание |
|----------|-----------------|----------------------|---------------|----------|
| Any	   | 0-65535	     |	Группа безопасности |	Self	    |	—      |
| TCP	   | 443			 |	CIDR				|	0.0.0.0/0 	|   —      |
| Any	   | 0-65535		 |	CIDR				|	0.0.0.0/0   |	—      |

Входящий трафик:
| Протокол | Диапазон портов |	Тип источника       | Источник      | Описание |
|----------|-----------------|----------------------|---------------|----------|
| Any	   | 0-65535		 |	Группа безопасности	|	Self	    |	—      |
| TCP	   | 22				 |  CIDR				|	0.0.0.0/0   | 	—      |
| ICMP	   | —				 |  CIDR				|	0.0.0.0/0   | 	—      |
| TCP	   | 80				 |  CIDR				|	0.0.0.0/0   | 	—      |

3) Подключиться по SSH с локальной машины и скопировать логин/пароль для подключения к AirFlow через web-интерфейс

		ssh dima@51.250.23.122

4) Переконфигурируем AirFlow, внеся изменения в /etc/airflow/airflow.cfg (чтобы выводилось меньше ненужной информации, напр. примеры DAG'ов)

		sudo nano /etc/airflow/airflow.cfg

	load_examples = False
	load_default_connections = False

	Сохраняем изменения и перезапускаем виртуальную машину

5) Генерируем SSH ключи на ВМ с AirFlow
	
		ssh-keygen

6) Переносим приватный ключ на директорию выше и присваиваем полный доступ (чтобы AirFlow мог его считать)

		cp .ssh/id_rsa ./
		sudo chmod 777 id_rsa

6) Копируем содержимое открытого ключа (он необходим при создании кластера Data Proc)

		cd .ssh
		cat id_rsa.pub
	Выделяем ключ и ctrl+shift+c

7) Создать кластер Data Proc:
 - при создании группа безопасности должна иметь такие же настройки, как и ВМ с AirFlow;
 - в качестве SSH ключа использовать открытый ключ ВМ с AirFlow (можно также добавить SSH своего ПК и открыть IP мастерноды внешнему миру, но это не рекомендуется);

8) Подключиться к мастерноде из консоли AirFlow можно по внутреннему IP адресу, можно по внешнему, если внешний ip был разрешен при создании кластера

		ssh ubuntu@10.129.0.33

9) Склонировать репозиторий, содержащий необходимый скрипт

		sudo apt update
		sudo apt install git
		git clone https://github.com/fds-git/MLOps.git

10) Установить необходимые библиотеки

		sudo apt install python3-pip
		sudo pip install numpy
		sudo pip install pandas
		sudo pip install fastparquet

11) Возвращаемся в консоль AirFlow и устанавливаем SSH провайдер

		sudo apt install python3-pip
		sudo pip install apache-airflow-providers-ssh

12) Проверяем, что провайдер установился
		
		sudo airflow providers list
		
13) Создаем новый DAG

		sudo nano /home/airflow/dags/run_generate_script.py

	Копируем содержимое run_generate_script.py из репозитория MLOps/airflow_dataproc_gen_data/for_airflow в только что созданный run_generate_script.py и сохраняем изменения (не забыть проверить, что remote_host в SSHHook соответствует IP адресу мастерноды)

14) Подключиться к AirFlow через web-интерфейс (логин и пароль находятся в консоли подключения к AirFlow по SSH)

		http://51.250.23.122:80/

	Здесь должны увидеть новый DAG generate_data

15) Запускаем переключателем DAG. Через некоторое время можем увидеть выполненные экземпляры DAG'a, внутри будут выполненные таски run_generate, в логах можно посмотреть результаты работы.